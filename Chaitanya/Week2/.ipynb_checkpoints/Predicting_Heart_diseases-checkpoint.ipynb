{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71a8e2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy.special import expit\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb740ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a matrix consisting of all data points excluding the ones that have 'NA' somewhere in them\n",
    "ar = []\n",
    "with open('framingham.csv', mode = 'r') as file:\n",
    "    csvFile = csv.reader(file)\n",
    "    for lines in csvFile:\n",
    "        if 'NA' in lines:\n",
    "            continue\n",
    "        else:\n",
    "            ar.append(lines)\n",
    "#making an array \"arr\" for training the model\n",
    "arr = []\n",
    "for i in range(1,2500):\n",
    "    arr.append(list(map(float,np.array(ar[i]))))\n",
    "arr = np.array(arr)\n",
    "shape = arr.shape\n",
    "columns = shape[1]\n",
    "rows = shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63bdaac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def f(z):\n",
    "    return expit(z)\n",
    "\n",
    "#this function will be used to calculate the loss; input is the values given by above funcition and the \n",
    "#corresponding y value\n",
    "\n",
    "def f_(a, b):\n",
    "    a = max(a, 1e-15) # add a small constant to avoid taking the log of 0\n",
    "    a = min(a, 1-1e-15) # subtract a small constant from 1 to avoid taking the log of 1\n",
    "    return float(-b*(math.log(a)) - (1-b)*(math.log(1-a)))\n",
    "#function used while verifying the result\n",
    "def _f_(a):\n",
    "\treturn a*a\n",
    "#used for the decsision boundary\n",
    "def f_des(a):\n",
    "    if a<=0.2:\n",
    "        return 0\n",
    "    else: \n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af4e743b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a matrix of only inputs\n",
    "x_ = arr[:,:columns-1]\n",
    "std = np.std(x_, axis = 0)\n",
    "x_ = x_ - np.mean(x_, axis = 0) #standardization\n",
    "x_ = x_/std #further standardization\n",
    "#making an array of ones, which will be appended to input matrix, mimicking the constant term, so we can include \n",
    "#the constant term in the weights vector itself \n",
    "one = np.ones(rows).reshape(-1,1) \n",
    "x_ = np.append(x_, one,1) #including constant term in the array of data x\n",
    "y = arr[:,columns-1].reshape(-1) #y vector\n",
    "_x = np.copy(x_)\n",
    "x = _x.transpose() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05fb9364",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.ones(columns)\n",
    "#random initialization of the cost function\n",
    "J_init =10\n",
    "J_final = 0\n",
    "delJ = J_init - J_final\n",
    "eps =  0.0000001\n",
    "alpha = 0.1\n",
    "#an array for keeping the track of costfunction\n",
    "J = []\n",
    "j =0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7981cd15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5197.69886179 5115.66203226 5074.87956059 ...  939.89557908  939.89557898\n",
      "  939.89557888]\n"
     ]
    }
   ],
   "source": [
    "while abs(delJ) > eps:\n",
    "\tz = np.matmul(w,x)\n",
    "\tp = np.array(list(map(f, z)))\n",
    "    #using the above obtained value to calculate the loss function\n",
    "\tstepx = np.array(list(map(f_, p, y)))\n",
    "    #Summing the loss function to get the costfunction\n",
    "\tJ_init = np.sum(stepx)\n",
    "    #gradient descent\n",
    "\tstep = np.matmul(p -y, _x)\n",
    "\tw = w - (alpha/rows)*step\n",
    "\tdelJ = J_init - J_final\n",
    "    #keeping an adaptive learning rate\n",
    "\tif J_init > J_final:\n",
    "\t\talpha = alpha/2\n",
    "\tJ_final = J_init\n",
    "\tJ.append(J_final)\n",
    "print(np.array(J))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d627d7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.22561639  0.5123258  -0.04616461  0.03385268  0.24858093 -0.00219044\n",
      "  0.0457432   0.06472547  0.01286083  0.10833806  0.32901194 -0.0154033\n",
      "  0.08629063 -0.06486411  0.20112551 -1.9921912 ]\n"
     ]
    }
   ],
   "source": [
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "672176c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.20208769 -1.86831216  2.25137351 ... -0.77559877 -1.3630722\n",
      " -2.17548441]\n"
     ]
    }
   ],
   "source": [
    "#making a matrix for testing the data\n",
    "arrt = []\n",
    "for i in range(2500, len(ar)):\n",
    "    arrt.append(list(map(float,np.array(ar[i]))))\n",
    "arrt = np.array(arrt)\n",
    "shapet = arrt.shape\n",
    "\n",
    "columns = shapet[1]\n",
    "rows = shapet[0]\n",
    "x_t = arrt[:,:columns-1]\n",
    "stdt = np.std(x_t, axis = 0)\n",
    "x_t = x_t - np.mean(x_t, axis = 0)\n",
    "x_t = x_t/stdt\n",
    "\n",
    "one = np.ones(rows).reshape(-1,1)\n",
    "x_t = np.append(x_t, one,1)\n",
    "y_t = arrt[:,columns-1].reshape(-1)\n",
    "xt = x_t.transpose()\n",
    "\n",
    "d = np.matmul(w, xt)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "907fbe9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. ... 0. 1. 0.]\n",
      "180.0\n",
      "289.0\n",
      "86.0\n",
      "203.0\n",
      "0.7502160760587727\n",
      "0.5222222222222223\n",
      "0.91246226821906\n",
      "(1157, 16)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "p = np.array(list(map(f, d)))\n",
    "#out contains the predicted output accn to the trained model\n",
    "out = (np.array(list(map(f_des,p)))).reshape(-1)\n",
    "#F has the record of erroneos outputs: '1's corresponds to false positives, '-1's corresponds to the false negatives\n",
    "F = out-y_t\n",
    "print((F))\n",
    "#prints the number of actual positives\n",
    "print(sum(y_t))\n",
    "#returns an array containing the square of each element of the error matrix F\n",
    "error = sum(list(map(_f_, F)))\n",
    "\n",
    "#prints the total number of erroneous outputs\n",
    "print(error)\n",
    "#calculating the number of false negatives and false positives\n",
    "f_neg = (error - sum(F))/2\n",
    "f_pos = (error + sum(F))/2\n",
    "#total number of positives\n",
    "t_pos = sum(y_t)\n",
    "t_neg = shape[0] - t_pos\n",
    "print(f_neg)\n",
    "print(f_pos)\n",
    "#overall accuracy:\n",
    "print(1-error/shapet[0])\n",
    "#accuracy in predicting positives:\n",
    "print((t_pos-f_neg)/t_pos)\n",
    "#accuracy in predicting negatives:\n",
    "print((t_neg - f_pos)/t_neg)      \n",
    "print(shapet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eaf8e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
