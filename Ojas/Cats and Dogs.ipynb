{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d57fa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, numpy as np, matplotlib.pyplot as plt, os\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms, datasets\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5803892a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset CustomImageFolder\n",
      "    Number of datapoints: 8000\n",
      "    Root location: /home/ojmaha/Documents/SoC/archive (1)/dog vs cat/dataset/training_set\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Grayscale(num_output_channels=1)\n",
      "               Resize(size=(50, 50), interpolation=bilinear, max_size=None, antialias=warn)\n",
      "               ToTensor()\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "# Set the path to your dataset folder\n",
    "dataset_path = '/home/ojmaha/Documents/SoC/archive (1)/dog vs cat/dataset/training_set'\n",
    "\n",
    "# Define the transformations to be applied to each image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize((50, 50)),  # Resize the images to a specific size\n",
    "    transforms.ToTensor(),          # Convert the images to tensors\n",
    "    ])\n",
    "\n",
    "# Function to check if a file is a valid JPEG image\n",
    "def is_valid_image(file_path):\n",
    "    try:\n",
    "        with Image.open(file_path) as img:\n",
    "            img.verify()\n",
    "            return True\n",
    "    except (IOError, SyntaxError) as e:\n",
    "        return False\n",
    "\n",
    "# Custom Dataset class to handle corrupted or non-JPEG files\n",
    "class CustomImageFolder(ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        path, target = self.samples[index]\n",
    "        if self.transform is not None:\n",
    "            try:\n",
    "                img = self.transform(Image.open(path))\n",
    "                return img, target\n",
    "            except (IOError, SyntaxError) as e:\n",
    "                pass\n",
    "\n",
    "# Create the CustomImageFolder dataset\n",
    "dataset = CustomImageFolder(root=dataset_path, transform=transform)\n",
    "\n",
    "# Create the DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=len(dataset), shuffle=True)\n",
    "\n",
    "for X, y in dataloader:\n",
    "    break  # Since we only need to iterate once to get the entire dataset\n",
    "\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5d1442c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50, 50])\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][0].shape\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4b892a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Select a cat image from the dataset\n",
    "cat_image_index = 7689  # Adjust this index according to the image you want to display\n",
    "\n",
    "# Access the image tensor from the dataset\n",
    "cat_image_tensor, f = dataset[cat_image_index]\n",
    "\n",
    "# Convert the image tensor to a NumPy array\n",
    "cat_image_np = cat_image_tensor.numpy()\n",
    "# Transpose the array to match the shape expected by Matplotlib (C, H, W -> H, W, C)\n",
    "cat_image_np = cat_image_np.transpose(1, 2, 0)\n",
    "\n",
    "# Display the cat image\n",
    "plt.imshow(cat_image_np)\n",
    "plt.axis('off')  # Turn off axis ticks and labels\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b010ec38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() # just run the init of parent class (nn.Module)\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5) # input is 1 image, 32 output channels, 5x5 kernel / window\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5) # input is 32, bc the first layer output 32. Then we say the output will be 64 channels, 5x5 kernel / window\n",
    "        self.conv3 = nn.Conv2d(64, 128, 5)\n",
    "\n",
    "        x = torch.randn(50,50).view(-1,1,50,50)\n",
    "        self._to_linear = None\n",
    "        self.convs(x)\n",
    "\n",
    "        self.fc1 = nn.Linear(self._to_linear, 512) #flattening.\n",
    "        self.fc2 = nn.Linear(512, 1) # 512 in, 2 out bc we're doing 2 classes (dog vs cat).\n",
    "\n",
    "    def convs(self, x):\n",
    "        # max pooling over 2x2\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), (2, 2))\n",
    "\n",
    "        if self._to_linear is None:\n",
    "            self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, self._to_linear)  # .view is reshape ... this flattens X before \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x) # bc this is our output layer. No activation here.\n",
    "        return x.squeeze(1)\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "516722b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "7200 800\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "for i in dataset:\n",
    "    X.append(torch.Tensor(i[0]).view(-1, 50, 50))\n",
    "\n",
    "X = torch.stack(X, dim=0)\n",
    "X = X/255.0\n",
    "y = torch.Tensor([i[1] for i in dataset])\n",
    "VAL_PCT = 0.1  # lets reserve 10% of our data for validation\n",
    "val_size = int(len(X)*VAL_PCT)\n",
    "print(val_size)\n",
    "\n",
    "train_X = X[:-val_size]\n",
    "train_y = y[:-val_size]\n",
    "\n",
    "test_X = X[-val_size:]\n",
    "test_y = y[-val_size:]\n",
    "print(len(train_X), len(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bbfca21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/72 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0102, grad_fn=<SelectBackward0>)\n",
      "tensor([0.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██▍                                         | 4/72 [00:02<00:32,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.1022, grad_fn=<SelectBackward0>)\n",
      "tensor([0.])\n",
      "tensor(-0.2868, grad_fn=<SelectBackward0>)\n",
      "tensor([0.])\n",
      "tensor(-0.6472, grad_fn=<SelectBackward0>)\n",
      "tensor([0.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███▋                                        | 6/72 [00:03<00:18,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.2946, grad_fn=<SelectBackward0>)\n",
      "tensor([0.])\n",
      "tensor(-2.3900, grad_fn=<SelectBackward0>)\n",
      "tensor([0.])\n",
      "tensor(-4.0758, grad_fn=<SelectBackward0>)\n",
      "tensor([0.])\n",
      "tensor(-6.3175, grad_fn=<SelectBackward0>)\n",
      "tensor([0.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████▉                                     | 10/72 [00:03<00:09,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-8.9702, grad_fn=<SelectBackward0>)\n",
      "tensor([0.])\n",
      "tensor(-11.9406, grad_fn=<SelectBackward0>)\n",
      "tensor([0.])\n",
      "tensor(-15.1722, grad_fn=<SelectBackward0>)\n",
      "tensor([0.])\n",
      "tensor(-18.6450, grad_fn=<SelectBackward0>)\n",
      "tensor([0.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|████████▎                                  | 14/72 [00:03<00:06,  9.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-22.0683, grad_fn=<SelectBackward0>)\n",
      "tensor([0.])\n",
      "tensor(-25.7313, grad_fn=<SelectBackward0>)\n",
      "tensor([0.])\n",
      "tensor(-29.2441, grad_fn=<SelectBackward0>)\n",
      "tensor([0.])\n",
      "tensor(-32.7236, grad_fn=<SelectBackward0>)\n",
      "tensor([0.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████████▊                                | 18/72 [00:03<00:04, 11.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-36.4075, grad_fn=<SelectBackward0>)\n",
      "tensor([0.])\n",
      "tensor(-39.6427, grad_fn=<SelectBackward0>)\n",
      "tensor([0.])\n",
      "tensor(-42.9296, grad_fn=<SelectBackward0>)\n",
      "tensor([0.])\n",
      "tensor(-46.0570, grad_fn=<SelectBackward0>)\n",
      "tensor([0.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████▏                             | 22/72 [00:04<00:03, 13.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-49.1154, grad_fn=<SelectBackward0>)\n",
      "tensor([0.])\n",
      "tensor(-51.9947, grad_fn=<SelectBackward0>)\n",
      "tensor([0.])\n",
      "tensor(-54.5294, grad_fn=<SelectBackward0>)\n",
      "tensor([0.])\n",
      "tensor(-57.1026, grad_fn=<SelectBackward0>)\n",
      "tensor([0.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████▌                           | 26/72 [00:04<00:03, 13.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-59.5736, grad_fn=<SelectBackward0>)\n",
      "tensor([0.])\n",
      "tensor(-62.1635, grad_fn=<SelectBackward0>)\n",
      "tensor([0.])\n",
      "tensor(-63.7761, grad_fn=<SelectBackward0>)\n",
      "tensor([0.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|████████████████▋                          | 28/72 [00:04<00:03, 12.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-65.4652, grad_fn=<SelectBackward0>)\n",
      "tensor([0.])\n",
      "tensor(-67.8439, grad_fn=<SelectBackward0>)\n",
      "tensor([0.])\n",
      "tensor(-69.5320, grad_fn=<SelectBackward0>)\n",
      "tensor([0.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|█████████████████▉                         | 30/72 [00:04<00:03, 12.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-70.8556, grad_fn=<SelectBackward0>)\n",
      "tensor([0.])\n",
      "tensor(-72.5173, grad_fn=<SelectBackward0>)\n",
      "tensor([0.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|███████████████████                        | 32/72 [00:05<00:03, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-73.5647, grad_fn=<SelectBackward0>)\n",
      "tensor([0.])\n",
      "tensor(-75.0595, grad_fn=<SelectBackward0>)\n",
      "tensor([0.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████████████████████▉                      | 35/72 [00:05<00:04,  8.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-76.3260, grad_fn=<SelectBackward0>)\n",
      "tensor([0.])\n",
      "tensor(-77.5618, grad_fn=<SelectBackward0>)\n",
      "tensor([0.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|██████████████████████                     | 37/72 [00:05<00:04,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-78.0946, grad_fn=<SelectBackward0>)\n",
      "tensor([0.])\n",
      "tensor(-79.0905, grad_fn=<SelectBackward0>)\n",
      "tensor([0.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|██████████████████████▋                    | 38/72 [00:06<00:05,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-80.0348, grad_fn=<SelectBackward0>)\n",
      "tensor([0.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|███████████████████████▎                   | 39/72 [00:06<00:05,  5.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-80.9075, grad_fn=<SelectBackward0>)\n",
      "tensor([0.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████████████████████████                  | 42/72 [00:06<00:04,  6.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-81.4407, grad_fn=<SelectBackward0>)\n",
      "tensor([1.])\n",
      "tensor(-68.9472, grad_fn=<SelectBackward0>)\n",
      "tensor([1.])\n",
      "tensor(-54.7676, grad_fn=<SelectBackward0>)\n",
      "tensor([1.])\n",
      "tensor(-40.8940, grad_fn=<SelectBackward0>)\n",
      "tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|███████████████████████████▍               | 46/72 [00:07<00:02, 10.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-29.1739, grad_fn=<SelectBackward0>)\n",
      "tensor([1.])\n",
      "tensor(-19.6741, grad_fn=<SelectBackward0>)\n",
      "tensor([1.])\n",
      "tensor(-12.6705, grad_fn=<SelectBackward0>)\n",
      "tensor([1.])\n",
      "tensor(-7.7784, grad_fn=<SelectBackward0>)\n",
      "tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|█████████████████████████████▊             | 50/72 [00:07<00:01, 12.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-4.5558, grad_fn=<SelectBackward0>)\n",
      "tensor([1.])\n",
      "tensor(-2.5126, grad_fn=<SelectBackward0>)\n",
      "tensor([1.])\n",
      "tensor(-1.3043, grad_fn=<SelectBackward0>)\n",
      "tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████████████████████████████            | 52/72 [00:07<00:01, 12.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.6313, grad_fn=<SelectBackward0>)\n",
      "tensor([1.])\n",
      "tensor(-0.2889, grad_fn=<SelectBackward0>)\n",
      "tensor([1.])\n",
      "tensor(-0.1338, grad_fn=<SelectBackward0>)\n",
      "tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|█████████████████████████████████▍         | 56/72 [00:07<00:01, 12.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0732, grad_fn=<SelectBackward0>)\n",
      "tensor([1.])\n",
      "tensor(-0.0456, grad_fn=<SelectBackward0>)\n",
      "tensor([1.])\n",
      "tensor(-0.0265, grad_fn=<SelectBackward0>)\n",
      "tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|██████████████████████████████████▋        | 58/72 [00:07<00:01, 12.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0132, grad_fn=<SelectBackward0>)\n",
      "tensor([1.])\n",
      "tensor(-0.0060, grad_fn=<SelectBackward0>)\n",
      "tensor([1.])\n",
      "tensor(0.0002, grad_fn=<SelectBackward0>)\n",
      "tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|█████████████████████████████████████      | 62/72 [00:08<00:00, 12.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0140, grad_fn=<SelectBackward0>)\n",
      "tensor([1.])\n",
      "tensor(0.0328, grad_fn=<SelectBackward0>)\n",
      "tensor([1.])\n",
      "tensor(0.0526, grad_fn=<SelectBackward0>)\n",
      "tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|██████████████████████████████████████▏    | 64/72 [00:08<00:00, 12.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0728, grad_fn=<SelectBackward0>)\n",
      "tensor([1.])\n",
      "tensor(0.0936, grad_fn=<SelectBackward0>)\n",
      "tensor([1.])\n",
      "tensor(0.1146, grad_fn=<SelectBackward0>)\n",
      "tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|████████████████████████████████████████▌  | 68/72 [00:08<00:00, 12.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1368, grad_fn=<SelectBackward0>)\n",
      "tensor([1.])\n",
      "tensor(0.1606, grad_fn=<SelectBackward0>)\n",
      "tensor([1.])\n",
      "tensor(0.1864, grad_fn=<SelectBackward0>)\n",
      "tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████████████████████████████████████▊ | 70/72 [00:08<00:00, 11.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2147, grad_fn=<SelectBackward0>)\n",
      "tensor([1.])\n",
      "tensor(0.2466, grad_fn=<SelectBackward0>)\n",
      "tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 72/72 [00:09<00:00,  7.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2830, grad_fn=<SelectBackward0>)\n",
      "tensor([1.])\n",
      "Epoch: 0. Loss: 0.5616323947906494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "BATCH_SIZE = 100\n",
    "EPOCHS = 1\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for i in tqdm(range(0, len(train_X), BATCH_SIZE)): # from 0, to the len of x, stepping BATCH_SIZE at a time. [:50] ..for now just to dev\n",
    "        batch_X = train_X[i:i+BATCH_SIZE].view(-1, 1, 50, 50)\n",
    "        batch_y = train_y[i:i + BATCH_SIZE].unsqueeze(1).float()\n",
    "\n",
    "        net.zero_grad()\n",
    "\n",
    "        outputs = net(batch_X)\n",
    "        print(outputs[0])\n",
    "        print(batch_y[0])\n",
    "        loss = loss_function(outputs, batch_y.view(100))\n",
    "        loss.backward()\n",
    "        optimizer.step()    # Does the update\n",
    "\n",
    "    print(f\"Epoch: {epoch}. Loss: {loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b7a9397",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 800/800 [00:00<00:00, 1119.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(len(test_X))):\n",
    "        real_class = torch.argmax(test_y[i])\n",
    "        net_out = net(test_X[i].view(-1, 1, 50, 50))[0]  # returns a list, \n",
    "        predicted_class = torch.argmax(net_out)\n",
    "\n",
    "        if predicted_class == real_class:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "print(\"Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e829163b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
