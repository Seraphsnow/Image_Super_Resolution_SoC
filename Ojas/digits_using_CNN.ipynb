{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2595a4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch ,torchvision, matplotlib.pyplot as plt\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "train = datasets.MNIST('', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "test = datasets.MNIST('', train=False, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23dcca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22f1801f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([9, 1, 3, 5, 3, 6, 9, 4, 8, 2])]\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.2510, 0.9529, 0.1647, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0667,\n",
      "          0.0196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.5373, 0.8235, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2667,\n",
      "          0.0627, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.2667, 0.9686, 0.4549, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.5294, 0.9922, 0.4549, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.6078, 0.9922, 0.0431, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.5216, 0.8314, 0.4627, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0353,\n",
      "          0.7725, 0.7608, 0.0314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1843,\n",
      "          0.9922, 0.6314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0353, 0.6863,\n",
      "          0.9922, 0.4667, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2588, 0.8314,\n",
      "          0.8706, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0431, 0.5882, 0.9961,\n",
      "          0.4784, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4549, 0.9961, 0.9922,\n",
      "          0.2706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5765, 0.9961, 0.8588,\n",
      "          0.0745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.3020, 0.9373, 0.9647, 0.3098,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.1255, 0.8980, 0.9922, 0.6980, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0196, 0.5451, 0.9961, 1.0000, 0.4157, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.1843, 0.9922, 0.9922, 0.7020, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.3098, 0.9922, 0.8941, 0.1882, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.6353, 0.9922, 0.4667, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0431, 0.8000, 0.8706, 0.0980, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "tensor(5)\n",
      "torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for x in trainset:\n",
    "    print(x)\n",
    "    break\n",
    "a , b = x[0][1] , x[1][3]\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "print(a.shape)\n",
    "plt.imshow(a.view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c2bd885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c79ab05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() # just run the init of parent class (nn.Module)\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3) # input is 1 image, 32 output channels, 5x5 kernel / window\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3) # input is 32, bc the first layer output 32. Then we say the output will be 64 channels, 5x5 kernel / window\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3)\n",
    "\n",
    "        x = torch.randn(28,28).view(-1,1,28,28)\n",
    "        self._to_linear = None\n",
    "        self.convs(x)\n",
    "\n",
    "        self.fc1 = nn.Linear(self._to_linear, 512) #flattening.\n",
    "        self.fc2 = nn.Linear(512, 64) \n",
    "        self.fc3 = nn.Linear(64, 10) #10 output classes cuz 10 digits\n",
    "\n",
    "    def convs(self, x):\n",
    "        # max pooling over 2x2\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), (2, 2))\n",
    "\n",
    "        if self._to_linear is None:\n",
    "            self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, self._to_linear)  # .view is reshape ... this flattens X before \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x) # bc this is our output layer. No activation here.\n",
    "        return F.softmax(x, dim=1)\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f39a5d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0992, 0.0847, 0.1024, 0.0879, 0.1053, 0.1138, 0.1083, 0.1048, 0.0898,\n",
      "         0.1037]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "Z = torch.randn((28,28))\n",
    "Z = Z.view(-1, 28, 28)\n",
    "output = net(Z)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3407b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.7989, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.9999, grad_fn=<NllLossBackward0>)\n",
      "tensor(-1., grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(3): # 3 full passes over the data\n",
    "    for data in trainset:  # `data` is a batch of data\n",
    "        X, y = data  # X is the batch of features, y is the batch of targets.\n",
    "        net.zero_grad()  # sets gradients to 0 before loss calc. You will do this likely every step.\n",
    "        output = net(X.view(-1,1,28,28))  # pass in the reshaped batch (recall they are 28x28 atm)\n",
    "        loss = F.nll_loss(output, y)  # calc and grab the loss value\n",
    "        loss.backward()  # apply this loss backwards thru the network's parameters\n",
    "        optimizer.step()  # attempt to optimize weights to account for loss/gradients\n",
    "    print(loss)  # print loss. We hope loss (a measure of wrong-ness) declines! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a114d3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.6052e-45, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4943e-43, 0.0000e+00,\n",
      "         0.0000e+00, 3.3659e-35, 0.0000e+00, 1.0000e+00],\n",
      "        [9.8091e-45, 3.6980e-42, 1.0000e+00, 0.0000e+00, 4.3138e-37, 0.0000e+00,\n",
      "         0.0000e+00, 1.2498e-41, 9.0570e-31, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [2.6583e-42, 2.1003e-37, 7.8974e-30, 0.0000e+00, 1.3415e-32, 1.0516e-29,\n",
      "         5.0051e-32, 0.0000e+00, 1.0000e+00, 1.0323e-33],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [2.2298e-26, 7.1824e-33, 1.0611e-26, 7.5231e-28, 1.0000e+00, 7.9178e-39,\n",
      "         2.0856e-22, 1.1107e-33, 1.2147e-39, 3.9591e-23],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00, 1.3764e-40, 0.0000e+00, 1.5975e-43, 1.8938e-31,\n",
      "         2.4932e-30, 2.3202e-33, 2.0879e-43, 3.0741e-24]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "735d2238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.956\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1,1,28,28))\n",
    "        #print(output)\n",
    "        for idx, i in enumerate(output):\n",
    "            #print(torch.argmax(i), y[idx])\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "print(\"Accuracy: \", round(correct/total, 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
